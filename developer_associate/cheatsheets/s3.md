# S3

- object based storage
- store unlimited amount of data without worry of underlying storage infrastructure
- replicates data across at least 3 AZs to ensure 99.99% availibility and 11' 9s of durability
- object contain your data (they are like files)
- objects can be size anywhere from 0 bytes up to 5 terrabytes
- bucket contain objects. bucket can also contain folders which can in turn can contain objects
- bucket names are unique across all AWS accounts - like a domain name
- when you upload a file to S3 successfully you will receive a HTTP 200 code
- **lifecycle management** objects can moved between storage classes or objects can be deleted automatically based on a schedule
- **versioning** objects are given a version id, when new objects are uploaded, the older objects are kept.
  - you can access any object version
  - when you delete an object, the prev object is restored
  - once versioning is turned on, it can't be turned off, only suspended
- **mfa device** enforce delete operations to require MFA token in order to delete an object
  - must have versioning turned on to use
  - can only turn on MFA from the AWS CLI
  - root account is only allowed to delete objects
- all new buckets are **private by default**
- logging can be turned on a bucket to log to track operations performed on objects
- **access control** is configured using **bucket policies** and **access control lists (ACL)**
- **bucket policies** are JSON documents which let you write complex control access
- **ACLs** are the legacy method (not depreciated) where you grant access to objects and buckets with the simple actions
- **security in transit** uploading files is done over SSL
- **SSE** stands for Server Side Encryption - S3 has **3 options** for SSE
  - **SSE-AES** S3 handles the key, uses AES-256 algorithm
  - **SSE-KMS** envelop encryption via AWS KMS and you manage the keys
  - **SSE-C** customer provided key (you manage the keys)
- **client side encryption** you must encrypt your own files before uploading them to S3
- **cross region replication (CRR)** allows you to repicate files across regions for greater durability. you must have versioning turned on in the source and destination bucket. you can have CRR replicate to bucket in another AWS account
- **transfer acceleration** provide faster and secure uploads from anywhere in the world. data is uploaded via distinct url to an edge location. data is then transported to your S3 bucket via AWS backbone network
- **presigned URLs** is a url generated via the AWS CLI and SDK. it provides temporary access to write or download object data. presigned URLs are commonly used to access private objects
- **S3 has 6 different storage classes**
  - **standard**
    - fast! 99.99% availibility
    - 11 9's durability
    - replicated across at least 3 AZs
  - **intelligent tiering**
    - uses machine learning to analyze your object usage and determine the appropriate storage class.
    - data is moved to the most cost-effective access tier, without any performance impact or added
  - **standard infrequenly accessed (IA)**
    - still fast!
    - cheaper is you access files less than once a month
    - additional retrieval fee is applied
    - 50% less than standard (redudced availibility)
  - **one zone IA**
    - still fast
    - objects only exists in one AZ
    - availibility is 99.5% but cheaper than standard IA by 20% less (reduce durability)
    - data could get destroyed
    - a retrieval fee is applied
  - **glacier** for long-term cold storage. retrieval of data can take minutes to hours but the off is very cheap storage
  - **glacier deep archive** the lowest cost storage class. data retrieval time is 12 hours
